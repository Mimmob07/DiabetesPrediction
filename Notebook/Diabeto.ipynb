{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import itertools\n",
                "import warnings\n",
                "import plotly.express as px\n",
                "from plotly.subplots import make_subplots\n",
                "import matplotlib.pyplot as plt\n",
                "import plotly.graph_objects as go\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.tree import plot_tree\n",
                "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.inspection import permutation_importance\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabetes = pd.read_csv(\"../diabetes.csv\")\n",
                "diabetes.iloc[:, 1:7] = diabetes.iloc[:, 1:7].replace(0, np.NaN)\n",
                "diabetes"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model to Predict Missing Values in Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# nanRows = diabetes[diabetes.isna().any(axis=1)]\n",
                "filledRows = diabetes.dropna()\n",
                "diabetesPredicted = diabetes.copy()\n",
                "for col in diabetes.columns:\n",
                "    tmpImputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
                "\n",
                "    if col == \"Pregnancies\" or col == \"DiabetesPedigreeFunction\" or col == \"Age\" or col == \"Outcome\":\n",
                "        continue\n",
                "    nanRows = diabetes[diabetes[col].isna()]\n",
                "     \n",
                "    filledRowsX = filledRows.drop(columns=[col])\n",
                "    filledRowsY = filledRows[[col]]\n",
                "    nanRowsX = nanRows.drop(columns=[col])\n",
                "    nanRowsY = nanRows[[col]]\n",
                "    for icol in nanRowsX.columns:\n",
                "        # nanRowsX[icol] = tmpImputer.fit_transform(nanRowsX[icol].values.reshape(-1, 1))\n",
                "        nanRowsX[icol].fillna(diabetes[icol].mean(), inplace=True)\n",
                "        \n",
                "    linRegModel = LinearRegression()\n",
                "    linRegModel.fit(filledRowsX, filledRowsY)\n",
                "    \n",
                "    linRegPred = linRegModel.predict(nanRowsX)\n",
                "    diabetesPredicted.loc[diabetesPredicted[col].isna(), col] = linRegPred\n",
                "\n",
                "display(diabetesPredicted)\n",
                "# bro we have to write a model for every row with missing values(6) SIX MODELS!!!!!!"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Simple Imputer to Replace Missing Values With the Average of the Column"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
                "\n",
                "for i in diabetes.columns:\n",
                "    diabetes[i]=imputer.fit_transform(diabetes[i].values.reshape(-1,1))\n",
                "    \n",
                "diabetes"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Correlation Between All Variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# diabetes.corr().style.background_gradient(cmap='winter_r').set_precision(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabetes.corr()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Balance Out The Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "px.histogram(diabetes, x='Outcome', color='Outcome', title='Visualization of Bias Before', width=500, height=500,\n",
                "             template='plotly_dark', color_discrete_sequence=['#F63366', '#00CC96'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabetesUB = diabetes.sort_values(\"Outcome\", ascending = False).reset_index(drop = True)\n",
                "oneCount = len(diabetesUB[diabetes.Outcome == 1])\n",
                "diabetesUB = diabetesUB.iloc[ :oneCount + oneCount, :]\n",
                "diabetesUB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "px.histogram(diabetesUB, x='Outcome', color='Outcome', title='Visualization of Bias After', width=500, height=500,\n",
                "             template='plotly_dark', color_discrete_sequence=['#F63366', '#00CC96'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spliting data for training and testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diabetes_x = diabetes.drop(columns=['Outcome'])\n",
                "diabetes_y = diabetes[\"Outcome\"]\n",
                "\n",
                "diabetesUB_x = diabetesUB.drop(columns=['Outcome'])\n",
                "diabetesUB_y = diabetesUB['Outcome']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(diabetes_x)\n",
                "\n",
                "X_scaledUB = scaler.fit_transform(diabetesUB_x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, diabetes_y, test_size=0.2, random_state=60)\n",
                "\n",
                "X_trainUB, X_testUB, Y_trainUB, Y_testUB = train_test_split(X_scaledUB, diabetesUB_y, test_size=0.3, random_state=60)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Detecting Outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for col in diabetesUB_x.columns:\n",
                "#     fig = px.box(diabetesUB_x,y=col,color=diabetesUB[\"Outcome\"],title=col,width=500,height=500,template=\"plotly_dark\")\n",
                "#     fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"Pregnancies\"], name=\"Pregnancies\"))\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"SkinThickness\"], name=\"SkinThickness\"))\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"BMI\"], name=\"BMI\"))\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"Age\"], name=\"Age\"))\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"DiabetesPedigreeFunction\"], name=\"DiabetesPedigreeFunction\"))\n",
                "\n",
                "fig.update_traces(boxpoints='all', jitter=0)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"Glucose\"], name=\"Glucose\"))\n",
                "fig.add_trace(go.Box(y=diabetesUB[\"BloodPressure\"], name=\"BloodPressure\"))\n",
                "\n",
                "fig.update_traces(boxpoints='all', jitter=0)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = go.Figure()\n",
                "\n",
                "for col in diabetesUB_x.columns:\n",
                "    if col == \"Insulin\":\n",
                "        continue\n",
                "    fig.add_trace(go.Box(y=diabetesUB[col], name=col))\n",
                "\n",
                "# fig.update_traces(boxpoints='all', jitter=0)\n",
                "fig.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training and Predicting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\"Age\",\"BMI\",\"DiabetesPedigreeFunction\"]\n",
                "scoreRelationship = pd.DataFrame(columns=[\"Model\", \"Accuracy Scores\"])\n",
                "f1Scores = pd.DataFrame(columns=[\"Model\", \"F1 Score 0\", \"F1 Score 1\"])\n",
                "ReScores = pd.DataFrame(columns=[\"Model\", \"Recall Score 0\", \"Recall Score 1\"])\n",
                "PrScores = pd.DataFrame(columns=[\"Model\", \"Precision Score 0\", \"Precision Score 1\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def allScores(Y_test, predict):\n",
                "    prc = precision_score(Y_test, predict, average=None)\n",
                "    rec = recall_score(Y_test, predict, average=None)\n",
                "    f1 = f1_score(Y_test, predict, average=None)\n",
                "    acc = accuracy_score(Y_test, predict)\n",
                "    return prc, rec, f1, acc"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Linear Regression Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "accScores = []\n",
                "f10 = []\n",
                "f11 = []\n",
                "re0 = []\n",
                "re1 = []\n",
                "pr0 = []\n",
                "pr1 = []\n",
                "\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=20)\n",
                "for train, test in kfold.split(diabetesPredicted):\n",
                "    train_x = diabetesPredicted.iloc[train, :8]\n",
                "    train_y = diabetesPredicted.iloc[train, 8]\n",
                "    test_x = diabetesPredicted.iloc[test, :8]\n",
                "    test_y = diabetesPredicted.iloc[test, 8]\n",
                "    linmodel = LinearRegression()\n",
                "    linmodel.fit(train_x, train_y)\n",
                "    linear_pred = (linmodel.predict(test_x) > 0.55) * 1\n",
                "    print(allScores(test_y, linear_pred))\n",
                "    linmodel_fi = permutation_importance(linmodel, train_x, train_y)\n",
                "    accScores.append(accuracy_score(test_y, linear_pred))\n",
                "    f1sc = f1_score(test_y, linear_pred, average=None)\n",
                "    resc = recall_score(test_y, linear_pred, average=None)\n",
                "    prsc = precision_score(test_y, linear_pred, average=None)\n",
                "    f10.append(f1sc[0])\n",
                "    f11.append(f1sc[1])\n",
                "    re0.append(resc[0])\n",
                "    re1.append(resc[1])\n",
                "    pr0.append(prsc[0])\n",
                "    pr1.append(prsc[1])\n",
                "\n",
                "scoreRelationship = pd.concat([scoreRelationship, pd.DataFrame({\"Model\": \"Linear Regression\", \"Accuracy Scores\":(sum(accScores) / 5)},index=[0])],ignore_index=True)\n",
                "f1Scores = pd.concat([f1Scores, pd.DataFrame({\"Model\":\"Linear Regression\", \"F1 Score 0\":(sum(f10)/5),  \"F1 Score 1\":(sum(f11)/5)},index=[0])],ignore_index=True)\n",
                "ReScores = pd.concat([ReScores, pd.DataFrame({\"Model\":\"Linear Regression\", \"Recall Score 0\":(sum(re0)/5),  \"Recall Score 1\":(sum(re1)/5)},index=[0])],ignore_index=True)\n",
                "PrScores = pd.concat([PrScores, pd.DataFrame({\"Model\":\"Linear Regression\", \"Precision Score 0\":(sum(pr0)/5),  \"Precision Score 1\":(sum(pr1)/5)},index=[0])],ignore_index=True)\n",
                "\n",
                "tmp = pd.DataFrame({'Feature': features, 'Feature importance': abs(linmodel_fi['importances_mean'])})\n",
                "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
                "fig=px.bar(tmp,x='Feature',y='Feature importance',color='Feature importance',title=\"Features Importance of Linear Regression Model\",\n",
                "            labels=dict(x=\"Feature\",y=\"Feature importance\",color=\"Feature importance\"),color_continuous_midpoint=0.8,\n",
                "            width=600,height=600,template=\"plotly_dark\")\n",
                "fig.show()\n",
                "\n",
                "cmLin = confusion_matrix(test_y, linear_pred)\n",
                "dispLin = ConfusionMatrixDisplay(confusion_matrix=cmLin)\n",
                "dispLin.plot()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Logistic Regression Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "accScores = []\n",
                "f10 = []\n",
                "f11 = []\n",
                "re0 = []\n",
                "re1 = []\n",
                "pr0 = []\n",
                "pr1 = []\n",
                "\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=20)\n",
                "for train, test in kfold.split(diabetesPredicted):\n",
                "    train_x = diabetesPredicted.iloc[train, :8]\n",
                "    train_y = diabetesPredicted.iloc[train, 8]\n",
                "    test_x = diabetesPredicted.iloc[test, :8]\n",
                "    test_y = diabetesPredicted.iloc[test, 8]\n",
                "    logreg_model = LogisticRegression(max_iter=30000)\n",
                "    logreg_model.fit(train_x, train_y)\n",
                "    logreg_pred = (logreg_model.predict_proba(test_x) > 0.6) * 1\n",
                "    print(allScores(test_y, logreg_pred[:,1]))\n",
                "    logmodel_fi = permutation_importance(linmodel, train_x, train_y)\n",
                "    accScores.append(accuracy_score(test_y, logreg_pred[:,1]))\n",
                "    f1sc = f1_score(test_y, logreg_pred[:,1], average=None)\n",
                "    resc = recall_score(test_y, logreg_pred[:,1], average=None)\n",
                "    prsc = precision_score(test_y, logreg_pred[:,1], average=None)\n",
                "    f10.append(f1sc[0])\n",
                "    f11.append(f1sc[1])\n",
                "    re0.append(resc[0])\n",
                "    re1.append(resc[1])\n",
                "    pr0.append(prsc[0])\n",
                "    pr1.append(prsc[1])\n",
                "\n",
                "scoreRelationship = pd.concat([scoreRelationship, pd.DataFrame({\"Model\": \"Logistic Regression\", \"Accuracy Scores\":(sum(accScores) / 5)},index=[0])],ignore_index=True)\n",
                "f1Scores = pd.concat([f1Scores, pd.DataFrame({\"Model\":\"Logistic Regression\", \"F1 Score 0\":(sum(f10)/5),  \"F1 Score 1\":(sum(f11)/5)},index=[0])],ignore_index=True)\n",
                "ReScores = pd.concat([ReScores, pd.DataFrame({\"Model\":\"Logistic Regression\", \"Recall Score 0\":(sum(re0)/5),  \"Recall Score 1\":(sum(re1)/5)},index=[0])],ignore_index=True)\n",
                "PrScores = pd.concat([PrScores, pd.DataFrame({\"Model\":\"Logistic Regression\", \"Precision Score 0\":(sum(pr0)/5),  \"Precision Score 1\":(sum(pr1)/5)},index=[0])],ignore_index=True)\n",
                "\n",
                "\n",
                "tmp = pd.DataFrame({'Feature': features, 'Feature importance': logmodel_fi['importances_mean']})\n",
                "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
                "fig=px.bar(tmp,x='Feature',y='Feature importance',color='Feature importance',title=\"Features Importance of Logistic Regression Model\",\n",
                "            labels=dict(x=\"Feature\",y=\"Feature importance\",color=\"Feature importance\"),color_continuous_midpoint=0.8,\n",
                "            width=600,height=600,template=\"plotly_dark\")\n",
                "fig.show()\n",
                "\n",
                "cmLog = confusion_matrix(test_y, logreg_pred[:,1])\n",
                "dispLog = ConfusionMatrixDisplay(confusion_matrix=cmLog)\n",
                "dispLog.plot()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Forest Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "accScores = []\n",
                "f10 = []\n",
                "f11 = []\n",
                "re0 = []\n",
                "re1 = []\n",
                "pr0 = []\n",
                "pr1 = []\n",
                "\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=20)\n",
                "for train, test in kfold.split(diabetesPredicted):\n",
                "    train_x = diabetesPredicted.iloc[train, :8]\n",
                "    train_y = diabetesPredicted.iloc[train, 8]\n",
                "    test_x = diabetesPredicted.iloc[test, :8]\n",
                "    test_y = diabetesPredicted.iloc[test, 8]\n",
                "    forestModel = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
                "    forestModel.fit(train_x, train_y)\n",
                "    forestModelPred = forestModel.predict(test_x)\n",
                "    print(allScores(test_y, forestModelPred))\n",
                "    accScores.append(accuracy_score(test_y, forestModelPred))\n",
                "    f1sc = f1_score(test_y, forestModelPred, average=None)\n",
                "    resc = recall_score(test_y, forestModelPred, average=None)\n",
                "    prsc = precision_score(test_y, forestModelPred, average=None)\n",
                "    f10.append(f1sc[0])\n",
                "    f11.append(f1sc[1])\n",
                "    re0.append(resc[0])\n",
                "    re1.append(resc[1])\n",
                "    pr0.append(prsc[0])\n",
                "    pr1.append(prsc[1])\n",
                "\n",
                "scoreRelationship = pd.concat([scoreRelationship, pd.DataFrame({\"Model\": \"Random Forest Classifier\", \"Accuracy Scores\":(sum(accScores) / 5)},index=[0])],ignore_index=True)\n",
                "f1Scores = pd.concat([f1Scores, pd.DataFrame({\"Model\":\"Random Forest Classifier\", \"F1 Score 0\":(sum(f10)/5),  \"F1 Score 1\":(sum(f11)/5)},index=[0])],ignore_index=True)\n",
                "ReScores = pd.concat([ReScores, pd.DataFrame({\"Model\":\"Random Forest Classifier\", \"Recall Score 0\":(sum(re0)/5),  \"Recall Score 1\":(sum(re1)/5)},index=[0])],ignore_index=True)\n",
                "PrScores = pd.concat([PrScores, pd.DataFrame({\"Model\":\"Random Forest Classifier\", \"Precision Score 0\":(sum(pr0)/5),  \"Precision Score 1\":(sum(pr1)/5)},index=[0])],ignore_index=True)\n",
                "\n",
                "\n",
                "tmp = pd.DataFrame({'Feature': features, 'Feature importance': forestModel.feature_importances_})\n",
                "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
                "fig=px.bar(tmp,x='Feature',y='Feature importance',color='Feature importance',title=\"Features Importance of Forest Model\",\n",
                "            labels=dict(x=\"Feature\",y=\"Feature importance\",color=\"Feature importance\"),color_continuous_midpoint=0.8,\n",
                "            width=600,height=600,template=\"plotly_dark\")\n",
                "fig.show()\n",
                "\n",
                "cmFor = confusion_matrix(test_y, forestModelPred)\n",
                "dispFor = ConfusionMatrixDisplay(confusion_matrix=cmFor)\n",
                "dispFor.plot()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(scoreRelationship.style)\n",
                "display(f1Scores.style)\n",
                "display(ReScores.style)\n",
                "display(PrScores.style)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Graph of our Tree Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plt.figure(figsize=(20,10))\n",
                "# plot_tree(forestModel,max_depth=3,fontsize=10,feature_names=train_x.columns.to_list())\n",
                "# plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![alt text](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/7304a882-5280-4444-9156-b330524036c6/d60uxie-5cd0ab54-acce-4454-818f-b6b05dc0e12f.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcLzczMDRhODgyLTUyODAtNDQ0NC05MTU2LWIzMzA1MjQwMzZjNlwvZDYwdXhpZS01Y2QwYWI1NC1hY2NlLTQ0NTQtODE4Zi1iNmIwNWRjMGUxMmYuanBnIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.YwRvA-feO5GcHeVtp8FAF3ECswTyouAREnVh8Pop3EI)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "https://www.kaggle.com/datasets/ashishkumarjayswal/diabetes-dataset"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TODO LIST\n",
                "\n",
                "* Code reward system from scratch\n",
                "* Create feature importance graph for each model (Done)\n",
                "* Train model to predict missing values in original dataset (Done)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
